{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle Finder CNN - Colab Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884804fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Install Required Packages\n",
    "!pip install shapely scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Dataset Class\n",
    "class CircleDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.files = [os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.json')]\n",
    "        self.transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a825e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "        with open(self.files[idx], 'r') as f:\n",
    "            data = json.load(f)\n",
    "        img = np.array(data['img'], dtype=np.float32)\n",
    "        label = data['label']\n",
    "        img = np.expand_dims(img, axis=0)  # Add channel dimension\n",
    "        target = torch.tensor([label['row'], label['col'], label['radius']], dtype=torch.float32)\n",
    "        return torch.tensor(img, dtype=torch.float32), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. CNN Model\n",
    "class CircleFinderCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CircleFinderCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Output: row, col, radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec36886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 64 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09914393",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Training Function\n",
    "def train_model(model, train_loader, val_loader, device, epochs=10, lr=1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a764a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for imgs, targets in train_loader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs, targets in val_loader:\n",
    "                imgs, targets = imgs.to(device), targets.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e71766",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Load Data and Train\n",
    "data_dir = './data'  # Ensure this folder contains your 1000 .json files\n",
    "full_dataset = CircleDataset(data_dir)\n",
    "train_idx, val_idx = train_test_split(list(range(len(full_dataset))), test_size=0.2)\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, val_idx)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f06594",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CircleFinderCNN()\n",
    "train_model(model, train_loader, val_loader, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Evaluate with IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e918a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bbe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(circ1_dict, circ2_dict):\n",
    "    shape1 = Point(circ1_dict['row'], circ1_dict['col']).buffer(circ1_dict['radius'])\n",
    "    shape2 = Point(circ2_dict['row'], circ2_dict['col']).buffer(circ2_dict['radius'])\n",
    "    return shape1.intersection(shape2).area / shape1.union(shape2).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, iou_threshold=0.7):\n",
    "    model.eval()\n",
    "    matches = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            outputs = model(imgs).cpu().numpy()\n",
    "            targets = targets.numpy()\n",
    "            for pred, true in zip(outputs, targets):\n",
    "                pred_dict = {'row': pred[0], 'col': pred[1], 'radius': pred[2]}\n",
    "                true_dict = {'row': true[0], 'col': true[1], 'radius': true[2]}\n",
    "                iou = intersection_over_union(pred_dict, true_dict)\n",
    "                if iou > iou_threshold:\n",
    "                    matches += 1\n",
    "                total += 1\n",
    "    accuracy = matches / total\n",
    "    print(f\"IoU > {iou_threshold} Accuracy: {accuracy:.2%}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbe99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, dataset, device, num_samples=5):\n",
    "    model.eval()\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    for i, idx in enumerate(indices):\n",
    "        img, true = dataset[idx]\n",
    "        with torch.no_grad():\n",
    "            pred = model(img.unsqueeze(0).to(device)).cpu().numpy()[0]\n",
    "        axs[i].imshow(img.squeeze(), cmap='gray')\n",
    "        axs[i].set_title(f\"True: ({int(true[0])}, {int(true[1])}, {int(true[2])})\\nPred: ({int(pred[0])}, {int(pred[1])}, {int(pred[2])})\")\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73cc647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some predictions\n",
    "show_predictions(model, val_dataset, device, num_samples=5)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
